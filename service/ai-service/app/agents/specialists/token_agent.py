"""
Token Usage Agent - ÌÜ†ÌÅ∞ ÏÇ¨Ïö©Îüâ Í≥ÑÏÇ∞ Ï†ÑÎ¨∏ AI
"""

import logging
from typing import Dict, Any

from app.core.schemas import TokenMetricScore
from app.orchestrator.context import ExecutionContext

logger = logging.getLogger(__name__)

class TokenUsageAgent:
    """
    ÌÜ†ÌÅ∞ ÏÇ¨Ïö©Îüâ Í≥ÑÏÇ∞ Ï†ÑÎ¨∏ AI Agent
    
    Ïó≠Ìï†:
    - ÌîÑÎ°¨ÌîÑÌä∏Ïùò ÌÜ†ÌÅ∞ Ïàò Í≥ÑÏÇ∞
    - Ìö®Ïú®ÏÑ± ÌèâÍ∞Ä
    - ÌÜ†ÌÅ∞ ÏµúÏ†ÅÌôî Ï†úÏïà
    """
    
    def __init__(self, context: ExecutionContext):
        self.context = context
        self.agent_name = "TokenUsageAgent"
    
    async def calculate_metric(self, agent_input: Dict[str, Any]) -> TokenMetricScore:
        """ÌÜ†ÌÅ∞ ÏÇ¨Ïö©Îüâ ÏßÄÌëú Í≥ÑÏÇ∞"""
        
        logger.info(f"üî¢ {self.agent_name} starting token usage calculation...")
        
        try:
            prompt = agent_input["prompt"]
            execution_results = agent_input["execution_results"]
            
            # Í∏∞Ï°¥ Tool Î°úÏßÅ Ïû¨ÏÇ¨Ïö©
            from app.agents.tools.tool_executor import ToolExecutor
            
            tool_executor = ToolExecutor(self.context)
            result = await tool_executor.execute_tool(
                "calculate_token_usage",
                {
                    "prompt": prompt,
                    "execution_results": execution_results
                }
            )
            
            if result.get("success"):
                score = result.get("score", 0.0)
                details = result.get("details", {})
                
                logger.info(f"‚úÖ {self.agent_name} completed - Token Score: {score}")
                
                return TokenMetricScore(
                    score=score,
                    details={
                        **details,
                        "agent": self.agent_name,
                        "calculation_method": "tiktoken_based"
                    }
                )
            else:
                logger.error(f"‚ùå {self.agent_name} calculation failed: {result.get('error')}")
                return TokenMetricScore(
                    score=0.0,
                    details={
                        "agent": self.agent_name,
                        "error": result.get("error", "Unknown error")
                    }
                )
                
        except Exception as e:
            logger.error(f"‚ùå {self.agent_name} failed with exception: {str(e)}")
            return TokenMetricScore(
                score=0.0,
                details={
                    "agent": self.agent_name,
                    "error": str(e)
                }
            )