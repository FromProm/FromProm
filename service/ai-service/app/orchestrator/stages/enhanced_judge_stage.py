"""
í–¥ìƒëœ í™˜ê° íƒì§€ ë‹¨ê³„
Claude ê¸°ë°˜ Claim ë¶„ì„ + MCP ì„ íƒ + Cohere Rerank + íŒë‹¨ LLM
Grounding Cacheë¡œ ì¤‘ë³µ ê²€ì¦ ìµœì†Œí™”
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional, Tuple
from enum import Enum

from app.orchestrator.context import ExecutionContext
from app.core.schemas import MetricScore, ExampleInput
from app.core.config import settings
from app.cache.grounding_cache import get_grounding_cache

logger = logging.getLogger(__name__)

class ClaimDomain(str, Enum):
    """Claim ë¶„ì•¼ ë¶„ë¥˜"""
    CURRENT_EVENTS = "current_events"      # ì‹œì‚¬/ìµœì‹  ì‚¬ê±´
    HISTORY_PEOPLE = "history_people"      # ì—­ì‚¬/ì¸ë¬¼/ì •ì˜  
    SCIENCE_RESEARCH = "science_research"  # ê³¼í•™/ì—°êµ¬/ìˆ˜ì‹
    ACADEMIC_PAPER = "academic_paper"      # í•™ìˆ  ë…¼ë¬¸
    GENERAL_SEARCH = "general_search"      # ì¼ë°˜ ê²€ìƒ‰

class MCPSource(str, Enum):
    """MCP ì†ŒìŠ¤ íƒ€ì…"""
    BRAVE_SEARCH = "brave_search"
    TAVILY_SEARCH = "tavily_search"
    WIKIPEDIA = "wikipedia"
    ACADEMIC_SEARCH = "academic_search"
    GOOGLE_SEARCH = "google_search"
    # ì‹¤ì œ MCP í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì§€ì›í•˜ëŠ” íƒ€ì…ë“¤ë§Œ ì‚¬ìš©

class EnhancedJudgeStage:
    """í–¥ìƒëœ í™˜ê° íƒì§€ ë‹¨ê³„"""

    def __init__(self, context: ExecutionContext):
        self.context = context

        # Grounding Cache ì´ˆê¸°í™”
        self.grounding_cache = get_grounding_cache() if settings.grounding_cache_enabled else None
        self._cache_hits = 0
        self._cache_misses = 0

        if self.grounding_cache:
            logger.info("EnhancedJudgeStage: Grounding Cache enabled")
        else:
            logger.info("EnhancedJudgeStage: Grounding Cache disabled")

        # MCP ë§¤í•‘ - Google Searchì™€ Tavily Searchë¥¼ ì£¼ë¡œ ì‚¬ìš©
        self.domain_to_mcp = {
            ClaimDomain.CURRENT_EVENTS: [MCPSource.GOOGLE_SEARCH, MCPSource.TAVILY_SEARCH],
            ClaimDomain.HISTORY_PEOPLE: [MCPSource.GOOGLE_SEARCH, MCPSource.WIKIPEDIA],
            ClaimDomain.SCIENCE_RESEARCH: [MCPSource.GOOGLE_SEARCH, MCPSource.ACADEMIC_SEARCH],
            ClaimDomain.ACADEMIC_PAPER: [MCPSource.GOOGLE_SEARCH, MCPSource.ACADEMIC_SEARCH],
            ClaimDomain.GENERAL_SEARCH: [MCPSource.GOOGLE_SEARCH, MCPSource.TAVILY_SEARCH]
        }
    
    async def execute(
        self, 
        example_inputs: List[ExampleInput], 
        execution_results: Dict[str, Any]
    ) -> MetricScore:
        """
        í–¥ìƒëœ í™˜ê° íƒì§€ ì‹¤í–‰
        1. Claudeë¡œ Claim ì¶”ì¶œ ë° ë¶„ì•¼ ë¶„ë¥˜
        2. MCP ì„ íƒ ë° ê·¼ê±° ìˆ˜ì§‘
        3. Cohere Rerank
        4. Lost in Middle ë°©ì§€ ì¬ë°°ì¹˜
        5. íŒë‹¨ LLMìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
        """
        logger.info("Starting enhanced hallucination detection")
        
        try:
            judge = self.context.get_judge()
            executions = execution_results['executions']
            
            # [1ë‹¨ê³„] Claudeë¡œ Claim ì¶”ì¶œ ë° ë¶„ì•¼ ë¶„ë¥˜
            logger.info("Step 1: Extracting and classifying claims...")
            classified_claims = await self._extract_and_classify_claims(judge, executions)
            
            logger.info(f"Extracted {len(classified_claims)} classified claims")
            for i, claim in enumerate(classified_claims):
                logger.info(f"  Claim {i+1}: [{claim.get('domain')}] {claim.get('claim', '')[:100]}...")
            
            if not classified_claims:
                logger.warning("No verifiable claims found - returning perfect score")
                return MetricScore(
                    score=100.0,
                    details={
                        'note': 'No verifiable claims found', 
                        'claims_processed': 0,
                        'reason': 'no_claims_extracted'
                    }
                )
            
            # [2ë‹¨ê³„] MCP ê¸°ë°˜ ê·¼ê±° ìˆ˜ì§‘
            logger.info("Step 2: Collecting evidence using MCP...")
            evidence_results = await self._collect_evidence_parallel(classified_claims)
            
            # [3ë‹¨ê³„] Cohere Rerank
            logger.info("Step 3: Reranking evidence with Cohere...")
            reranked_results = await self._rerank_evidence_parallel(evidence_results)
            
            # [4ë‹¨ê³„] Lost in Middle ë°©ì§€ ì¬ë°°ì¹˜
            logger.info("Step 4: Rearranging evidence to prevent lost in middle...")
            rearranged_results = self._rearrange_evidence(reranked_results)
            
            # [5ë‹¨ê³„] íŒë‹¨ LLMìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
            logger.info("Step 5: Scoring claims with judgment LLM...")
            claim_scores = await self._score_claims_parallel(judge, rearranged_results)
            
            # ìµœì¢… ì ìˆ˜ ê³„ì‚°
            final_score = self._calculate_final_score(claim_scores)

            # ìºì‹œ í†µê³„
            cache_stats = self._get_cache_stats()

            details = {
                'claims_processed': len(classified_claims),
                'claim_scores': claim_scores,
                'average_score': final_score,
                'methodology': 'Enhanced MCP-based fact verification with Cohere reranking',
                'grounding_cache': cache_stats
            }

            logger.info(f"Enhanced hallucination detection completed: {final_score:.3f}")
            logger.info(f"ğŸ“Š [GroundingCache] Stats - Hits: {cache_stats['cache_hits']}, Misses: {cache_stats['cache_misses']}, Hit Rate: {cache_stats['hit_rate']}")
            return MetricScore(score=final_score, details=details)
            
        except Exception as e:
            logger.error(f"Enhanced hallucination detection failed: {str(e)}")
            return MetricScore(score=0.0, details={'error': str(e)})
    
    async def _extract_and_classify_claims(
        self, 
        judge, 
        executions: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Claudeë¡œ Claim ì¶”ì¶œ, í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¶„ì•¼ ë¶„ë¥˜"""
        
        all_outputs = []
        for exec_data in executions:
            outputs = exec_data.get('outputs', [])
            all_outputs.extend([output for output in outputs if output.strip()])
        
        logger.info(f"Analyzing {len(all_outputs)} non-empty outputs for claims")
        
        if not all_outputs:
            logger.warning("No valid outputs to analyze")
            return []
        
        # ì¶œë ¥ ë‚´ìš© ìƒ˜í”Œ ë¡œê¹…
        for i, output in enumerate(all_outputs[:3]):  # ì²˜ìŒ 3ê°œë§Œ
            logger.info(f"Sample output {i+1}: {output[:200]}...")
        
        # Claudeì—ê²Œ Claim ì¶”ì¶œ, í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¶„ë¥˜ ìš”ì²­
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë“¤ì—ì„œ ì‚¬ì‹¤ ê²€ì¦ì´ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì£¼ì¥(claim)ë“¤ì„ ì¶”ì¶œí•˜ê³ , ê° ì£¼ì¥ì˜ í•µì‹¬ í‚¤ì›Œë“œì™€ ë¶„ì•¼ë¥¼ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸ë“¤:
""" + "\n".join([f"{i+1}. {output}" for i, output in enumerate(all_outputs)]) + """

ë¶„ë¥˜ ê¸°ì¤€:
- current_events: ì‹œì‚¬, ìµœì‹  ì‚¬ê±´, ë‰´ìŠ¤
- history_people: ì—­ì‚¬ì  ì‚¬ì‹¤, ì¸ë¬¼ ì •ë³´, ì •ì˜
- science_research: ê³¼í•™ì  ì‚¬ì‹¤, ì—°êµ¬ ê²°ê³¼, ìˆ˜ì‹
- academic_paper: í•™ìˆ  ë…¼ë¬¸, ì—°êµ¬ ë…¼ë¬¸
- general_search: ì¼ë°˜ì ì¸ ì‚¬ì‹¤, ìƒì‹, ê¸°íƒ€

í‚¤ì›Œë“œ ì¶”ì¶œ ê·œì¹™:
- ê° ì£¼ì¥ì—ì„œ ê²€ì¦ì— í•„ìš”í•œ í•µì‹¬ í‚¤ì›Œë“œ 2-4ê°œ ì¶”ì¶œ
- ì¸ëª…, ê³ ìœ ëª…ì‚¬, ì „ë¬¸ìš©ì–´, í•µì‹¬ ê°œë… ìœ„ì£¼
- ì˜ˆ: "1950ë…„ëŒ€: ì•Œë€ íŠœë§ì´ ì¸ê³µì§€ëŠ¥ ê°œë…ì„ ì œì•ˆ" â†’ ["ì•Œë€ íŠœë§", "ì¸ê³µì§€ëŠ¥", "1950ë…„ëŒ€"]

ê° ì£¼ì¥ì„ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:

[
  {
    "claim": "êµ¬ì²´ì ì¸ ì£¼ì¥ ë‚´ìš©",
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
    "domain": "ë¶„ì•¼_ì½”ë“œ",
    "confidence": 0.9
  }
]

ì¤‘ìš”: 
- JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”
- ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ì½”ë©˜íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- ìœ íš¨í•œ JSON í˜•ì‹ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì„¸ìš”
- keywordsëŠ” ë°˜ë“œì‹œ ë°°ì—´ í˜•íƒœë¡œ ì œê³µí•˜ì„¸ìš”

ê²€ì¦ ë¶ˆê°€ëŠ¥í•œ ì£¼ê´€ì  ì˜ê²¬ì´ë‚˜ ì°½ì‘ ë‚´ìš©ì€ ì œì™¸í•˜ê³ , ê°ê´€ì ìœ¼ë¡œ ì°¸/ê±°ì§“ì„ íŒë‹¨í•  ìˆ˜ ìˆëŠ” ì£¼ì¥ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”."""

        try:
            logger.info("Sending claim extraction request to Claude...")
            result = await judge.analyze_text(prompt)
            logger.info(f"Claude response length: {len(result)} characters")
            logger.info(f"Claude response preview: {result[:500]}...")
            
            # JSON íŒŒì‹± ì‹œë„
            import json
            import re
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë” ì •í™•í•œ ë°©ë²•)
            json_match = re.search(r'\[.*?\]', result, re.DOTALL)
            if json_match:
                json_text = json_match.group().strip()
                logger.info(f"Extracted JSON: {json_text[:300]}...")
                
                # JSON ìœ íš¨ì„± ê²€ì‚¬ ë° ì •ë¦¬
                try:
                    claims_data = json.loads(json_text)
                except json.JSONDecodeError as e:
                    logger.warning(f"First JSON parse failed: {e}")
                    # ë” ì—„ê²©í•œ JSON ì¶”ì¶œ ì‹œë„
                    lines = result.split('\n')
                    json_lines = []
                    in_json = False
                    bracket_count = 0
                    
                    for line in lines:
                        line = line.strip()
                        if line.startswith('['):
                            in_json = True
                            bracket_count = line.count('[') - line.count(']')
                            json_lines.append(line)
                        elif in_json:
                            bracket_count += line.count('[') - line.count(']')
                            json_lines.append(line)
                            if bracket_count <= 0:
                                break
                    
                    if json_lines:
                        json_text = '\n'.join(json_lines)
                        logger.info(f"Cleaned JSON: {json_text[:300]}...")
                        claims_data = json.loads(json_text)
                    else:
                        raise e
                logger.info(f"Parsed {len(claims_data)} claims from JSON")
                
                # ìœ íš¨í•œ ë„ë©”ì¸ë§Œ í•„í„°ë§
                valid_domains = [domain.value for domain in ClaimDomain]
                filtered_claims = []
                
                for claim_data in claims_data:
                    claim_text = claim_data.get('claim', '')
                    keywords = claim_data.get('keywords', [])
                    domain = claim_data.get('domain', '')
                    
                    if (domain in valid_domains and 
                        claim_text and 
                        len(claim_text) > 10 and
                        isinstance(keywords, list)):
                        
                        # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ìë™ ì¶”ì¶œ (fallback)
                        if not keywords:
                            logger.warning(f"No keywords provided for claim, using fallback extraction")
                            keywords = self._extract_keywords_fallback(claim_text)
                        
                        claim_data['keywords'] = keywords
                        filtered_claims.append(claim_data)
                        logger.info(f"Valid claim: [{domain}] {claim_text[:100]}... | Keywords: {keywords}")
                    else:
                        logger.warning(f"Invalid claim filtered out: [{domain}] {claim_text[:50]}... | Keywords: {keywords}")
                
                logger.info(f"Final filtered claims: {len(filtered_claims)}")
                return filtered_claims
            else:
                logger.error("No JSON array found in Claude response")
                logger.error(f"Full response: {result}")
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing failed: {str(e)}")
            if 'json_text' in locals():
                logger.error(f"Problematic JSON (first 500 chars): {json_text[:500]}")
                logger.error(f"Problematic JSON (last 500 chars): {json_text[-500:]}")
            else:
                logger.error("No JSON text extracted from response")
                logger.error(f"Full Claude response: {result[:1000]}")
        except Exception as e:
            logger.error(f"Claim extraction failed: {str(e)}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
        
        return []
    
    def _extract_keywords_fallback(self, claim_text: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ fallback ë¡œì§"""
        import re
        
        # ì¸ëª… ì¶”ì¶œ (í•œê¸€ ì´ë¦„, ì˜ë¬¸ ì´ë¦„)
        names = re.findall(r'[A-Z][a-z]+\s+[A-Z][a-z]+|[ê°€-í£]{2,4}', claim_text)
        
        # ìˆ«ì/ì—°ë„ ì¶”ì¶œ
        years = re.findall(r'\d{4}ë…„ëŒ€?|\d{4}ë…„', claim_text)
        
        # í•µì‹¬ ëª…ì‚¬ ì¶”ì¶œ (ì¡°ì‚¬ ì œê±°)
        nouns = re.findall(r'([ê°€-í£]{2,10})(?:ì´ë¼ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜|ì—ì„œ|ìœ¼ë¡œ)', claim_text)
        
        # ì˜ë¬¸ ì „ë¬¸ìš©ì–´
        english_terms = re.findall(r'[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*', claim_text)
        
        # ì¡°í•©
        keywords = []
        keywords.extend(names[:2])
        keywords.extend(years[:1])
        keywords.extend(nouns[:2])
        keywords.extend(english_terms[:1])
        
        # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ 4ê°œ
        unique_keywords = []
        for kw in keywords:
            if kw not in unique_keywords and len(kw) > 1:
                unique_keywords.append(kw)
        
        return unique_keywords[:4] if unique_keywords else [claim_text[:30]]
    
    async def _collect_evidence_parallel(
        self, 
        classified_claims: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """MCPë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ë¡œ ê·¼ê±° ìˆ˜ì§‘"""
        
        tasks = []
        for claim_data in classified_claims:
            task = self._collect_evidence_for_claim(claim_data)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        evidence_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Evidence collection failed for claim {i}: {str(result)}")
                # ì‹¤íŒ¨í•œ ê²½ìš° ë¹ˆ ê·¼ê±°ë¡œ ì²˜ë¦¬
                evidence_results.append({
                    **classified_claims[i],
                    'evidence': [],
                    'mcp_used': 'failed'
                })
            else:
                evidence_results.append(result)
        
        return evidence_results
    
    async def _collect_evidence_for_claim(self, claim_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ Claimì— ëŒ€í•œ ê·¼ê±° ìˆ˜ì§‘ - ê° í‚¤ì›Œë“œë‹¹ 5ê°œì”© ìˆ˜ì§‘"""
        
        domain = ClaimDomain(claim_data['domain'])
        claim_text = claim_data['claim']
        keywords = claim_data.get('keywords', [])
        
        # ë„ë©”ì¸ì— ë”°ë¥¸ MCP ì„ íƒ
        available_mcps = self.domain_to_mcp.get(domain, [MCPSource.GOOGLE_SEARCH, MCPSource.BRAVE_SEARCH])
        
        try:
            all_evidence = []
            mcp_used = []
            
            # ê° í‚¤ì›Œë“œì— ëŒ€í•´ ê·¼ê±° ìˆ˜ì§‘
            for keyword in keywords:
                logger.info(f"Collecting evidence for keyword: '{keyword}'")
                
                # ê° MCP ì†ŒìŠ¤ì—ì„œ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ (í‚¤ì›Œë“œë‹¹ 5ê°œ)
                for mcp_source in available_mcps[:2]:  # ìµœëŒ€ 2ê°œ ì†ŒìŠ¤ ì‚¬ìš©
                    try:
                        evidence = await self._call_mcp_for_evidence(mcp_source, keyword, limit=5)
                        
                        # í‚¤ì›Œë“œ ì •ë³´ ì¶”ê°€
                        for ev in evidence:
                            ev['search_keyword'] = keyword
                        
                        all_evidence.extend(evidence)
                        
                        if mcp_source.value not in mcp_used:
                            mcp_used.append(mcp_source.value)
                        
                        logger.info(f"  - {mcp_source.value}: {len(evidence)} items for '{keyword}'")
                    except Exception as e:
                        logger.warning(f"  - {mcp_source.value} failed for '{keyword}': {str(e)}")
            
            logger.info(f"Total collected: {len(all_evidence)} evidence items from {len(keywords)} keywords")
            
            return {
                **claim_data,
                'evidence': all_evidence,
                'mcp_used': mcp_used,
                'keywords_searched': keywords
            }
            
        except Exception as e:
            logger.error(f"Evidence collection failed: {str(e)}")
            return {
                **claim_data,
                'evidence': [],
                'mcp_used': 'failed'
            }
    
    async def _call_mcp_for_evidence(
        self, 
        mcp_source: MCPSource, 
        claim_text: str, 
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """MCP í˜¸ì¶œí•˜ì—¬ ê·¼ê±° ìˆ˜ì§‘ - ì‹¤ì œ êµ¬í˜„"""
        
        try:
            # MCP í´ë¼ì´ì–¸íŠ¸ import
            from app.adapters.mcp.mcp_client import MCPClient, MCPServerType
            
            # MCP ì†ŒìŠ¤ë¥¼ ì„œë²„ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
            source_mapping = {
                MCPSource.BRAVE_SEARCH: MCPServerType.BRAVE_SEARCH,
                MCPSource.TAVILY_SEARCH: MCPServerType.TAVILY_SEARCH,
                MCPSource.WIKIPEDIA: MCPServerType.WIKIPEDIA,
                MCPSource.ACADEMIC_SEARCH: MCPServerType.ACADEMIC_SEARCH,
                MCPSource.GOOGLE_SEARCH: MCPServerType.GOOGLE_SEARCH
            }
            
            server_type = source_mapping.get(mcp_source)
            if not server_type:
                logger.error(f"Unsupported MCP source: {mcp_source}")
                return []
            
            # ì‹¤ì œ MCP í´ë¼ì´ì–¸íŠ¸ë¡œ ê²€ìƒ‰
            mcp_client = MCPClient()
            evidence = await mcp_client.search_evidence(server_type, claim_text, limit)
            
            logger.info(f"MCP {mcp_source.value} returned {len(evidence)} evidence items")
            return evidence
            
        except Exception as e:
            logger.error(f"MCP call failed for {mcp_source}: {str(e)}")
            return []
    
    async def _rerank_evidence_parallel(
        self, 
        evidence_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Cohere Rerankerë¡œ ë³‘ë ¬ ì¬ìˆœìœ„í™”"""
        
        tasks = []
        for evidence_data in evidence_results:
            if evidence_data['evidence']:
                task = self._rerank_single_evidence(evidence_data)
                tasks.append(task)
            else:
                # ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
                tasks.append(asyncio.create_task(self._return_as_is(evidence_data)))
        
        return await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _rerank_single_evidence(self, evidence_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ Claimì˜ ê·¼ê±°ë¥¼ Cohereë¡œ ì¬ìˆœìœ„í™”"""
        
        claim_text = evidence_data['claim']
        evidence_list = evidence_data['evidence']
        
        logger.info(f"Reranking {len(evidence_list)} evidence items for claim: {claim_text[:50]}...")
        
        try:
            # ì‹¤ì œ AWS Bedrock Cohere Rerank í˜¸ì¶œ
            from app.adapters.reranker.cohere_reranker import CohereReranker
            
            reranker = CohereReranker()
            reranked_evidence = await reranker.rerank_evidence_list(
                claim=claim_text,
                evidence_list=evidence_list,
                top_k=min(15, len(evidence_list))  # ìµœëŒ€ 15ê°œê¹Œì§€ ìœ ì§€
            )
            
            logger.info(f"Cohere rerank completed: {len(reranked_evidence)} items retained")
            
            return {
                **evidence_data,
                'evidence': reranked_evidence,
                'reranked': True,
                'rerank_method': 'cohere_bedrock',
                'original_count': len(evidence_list),
                'reranked_count': len(reranked_evidence)
            }
            
        except Exception as e:
            logger.error(f"Cohere reranking failed: {str(e)}, using fallback")
            
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì •ë ¬ë¡œ í´ë°±
            await asyncio.sleep(0.05)
            
            # Fallback: relevance_score ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            reranked_evidence = sorted(
                evidence_list, 
                key=lambda x: x.get('relevance_score', 0), 
                reverse=True
            )[:15]  # ìµœëŒ€ 15ê°œ
            
            # Rerank ì ìˆ˜ ì¶”ê°€
            for i, evidence in enumerate(reranked_evidence):
                evidence['rerank_score'] = 1.0 - (i * 0.05)
                evidence['rerank_position'] = i + 1
            
            return {
                **evidence_data,
                'evidence': reranked_evidence,
                'reranked': True,
                'rerank_method': 'fallback_relevance',
                'rerank_error': str(e),
                'original_count': len(evidence_list),
                'reranked_count': len(reranked_evidence)
            }
    
    async def _return_as_is(self, evidence_data: Dict[str, Any]) -> Dict[str, Any]:
        """ê·¼ê±°ê°€ ì—†ëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜"""
        return {**evidence_data, 'reranked': False}
    
    def _rearrange_evidence(
        self, 
        reranked_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Lost in Middle ë°©ì§€ë¥¼ ìœ„í•œ ê·¼ê±° ì¬ë°°ì¹˜"""
        
        rearranged_results = []
        
        for evidence_data in reranked_results:
            if isinstance(evidence_data, Exception):
                logger.error(f"Reranking failed: {str(evidence_data)}")
                continue
                
            evidence_list = evidence_data.get('evidence', [])
            
            if len(evidence_list) <= 3:
                # 3ê°œ ì´í•˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                rearranged_evidence = evidence_list
            else:
                # Lost in Middle ë°©ì§€ ì¬ë°°ì¹˜
                # ê°€ì¥ ì¤‘ìš”í•œ ê²ƒë“¤ì„ ì²˜ìŒê³¼ ëì— ë°°ì¹˜
                rearranged_evidence = self._apply_lost_in_middle_prevention(evidence_list)
            
            rearranged_results.append({
                **evidence_data,
                'evidence': rearranged_evidence,
                'rearranged': True
            })
        
        return rearranged_results
    
    def _apply_lost_in_middle_prevention(self, evidence_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Lost in Middle ë°©ì§€ ì•Œê³ ë¦¬ì¦˜ ì ìš©"""
        
        if len(evidence_list) <= 3:
            return evidence_list
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì´ë¯¸ rerankë¨)
        sorted_evidence = sorted(
            evidence_list, 
            key=lambda x: x.get('rerank_score', x.get('relevance_score', 0)), 
            reverse=True
        )
        
        # ì¬ë°°ì¹˜: [1ìœ„, 2ìœ„, 3ìœ„, 7ìœ„, 8ìœ„, 9ìœ„, 10ìœ„, 6ìœ„, 5ìœ„, 4ìœ„]
        rearranged = []
        
        # ì²˜ìŒ 3ê°œ (1ìœ„, 2ìœ„, 3ìœ„) - ë†’ì€ ì ìˆ˜ë“¤ì„ ì•ì—
        for i in range(min(3, len(sorted_evidence))):
            rearranged.append(sorted_evidence[i])
        
        # ì¤‘ê°„ ë‚®ì€ ì ìˆ˜ë“¤ (7ìœ„ë¶€í„° ëê¹Œì§€) - ê°€ì¥ ë‚®ì€ ì ìˆ˜ë“¤ì„ ì¤‘ê°„ì—
        if len(sorted_evidence) > 6:
            for i in range(6, len(sorted_evidence)):
                rearranged.append(sorted_evidence[i])
        
        # ë§ˆì§€ë§‰ì— 6ìœ„, 5ìœ„, 4ìœ„ ìˆœì„œë¡œ (ì—­ìˆœ) - ì¤‘ê°„ ì ìˆ˜ë“¤ì„ ëì—
        if len(sorted_evidence) > 3:
            for i in range(min(6, len(sorted_evidence)) - 1, 2, -1):
                if i < len(sorted_evidence):
                    rearranged.append(sorted_evidence[i])
        
        return rearranged
    
    async def _score_claims_parallel(
        self, 
        judge, 
        rearranged_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """íŒë‹¨ LLMìœ¼ë¡œ ë³‘ë ¬ ì ìˆ˜ ê³„ì‚°"""
        
        tasks = []
        for evidence_data in rearranged_results:
            task = self._score_single_claim(judge, evidence_data)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        scored_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Claim scoring failed for claim {i}: {str(result)}")
                scored_results.append({
                    **rearranged_results[i],
                    'score': 50.0,  # ì¤‘ê°„ ì ìˆ˜
                    'scoring_error': str(result)
                })
            else:
                scored_results.append(result)
        
        return scored_results
    
    async def _score_single_claim(
        self,
        judge,
        evidence_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ Claimì— ëŒ€í•œ ì ìˆ˜ ê³„ì‚° - ì¬ì •ë ¬ëœ ê·¼ê±° ê¸°ë°˜ (Grounding Cache ì ìš©)"""

        claim_text = evidence_data['claim']
        evidence_list = evidence_data.get('evidence', [])
        keywords = evidence_data.get('keywords', [])

        # 1. ìºì‹œ ì¡°íšŒ (í™œì„±í™”ëœ ê²½ìš°)
        if self.grounding_cache:
            cached = await self.grounding_cache.get(claim_text)
            if cached:
                self._cache_hits += 1
                logger.info(f"ğŸ¯ [GroundingCache] HIT - Skipping LLM scoring for: {claim_text[:40]}...")
                return {
                    **evidence_data,
                    'score': 100.0 if cached['is_verified'] else 30.0,
                    'reasoning': f"[CACHED] {cached['evidence']}",
                    'cache_hit': True,
                    'cached_at': cached.get('created_at', '')
                }
            self._cache_misses += 1
            logger.debug(f"âŒ [GroundingCache] MISS - Scoring claim: {claim_text[:40]}...")

        if not evidence_list:
            # ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ë‚®ì€ ì ìˆ˜ (ê²€ì¦ ë¶ˆê°€)
            result = {
                **evidence_data,
                'score': 30.0,
                'reasoning': 'No evidence available for verification - likely hallucination'
            }
            # ìºì‹œì— ì €ì¥ (ê·¼ê±° ì—†ìŒë„ ìºì‹±)
            if self.grounding_cache:
                await self.grounding_cache.set(
                    claim_text,
                    is_verified=False,
                    evidence="ê·¼ê±° ì—†ìŒ - ê²€ì¦ ë¶ˆê°€",
                    mcp_sources=[],
                    confidence=0.3
                )
            return result
        
        # ê·¼ê±°ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„± (rerank_score ìˆœì„œëŒ€ë¡œ ì´ë¯¸ ì •ë ¬ë¨)
        evidence_text = "\n\n".join([
            f"ê·¼ê±° {i+1} (ê´€ë ¨ë„: {evidence.get('rerank_score', 0):.2f}):\n"
            f"ì œëª©: {evidence.get('title', '')}\n"
            f"ë‚´ìš©: {evidence.get('content', '')}\n"
            f"ì¶œì²˜: {evidence.get('url', '')}"
            for i, evidence in enumerate(evidence_list[:10])  # ìƒìœ„ 10ê°œë§Œ ì‚¬ìš©
        ])
        
        # íŒë‹¨ LLMì—ê²Œ ì ìˆ˜ ìš”ì²­
        scoring_prompt = f"""ë‹¤ìŒ ì£¼ì¥(claim)ì— ëŒ€í•´ ì œê³µëœ ê·¼ê±°ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ì‹¤ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³  0-100ì ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”.

ì£¼ì¥: {claim_text}

ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(keywords)}

ê·¼ê±°ë“¤ (ê´€ë ¨ë„ ìˆœìœ¼ë¡œ ì •ë ¬ë¨):
{evidence_text}

í‰ê°€ ê¸°ì¤€:
- 100ì : ê·¼ê±°ë“¤ì´ ì£¼ì¥ì„ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë’·ë°›ì¹¨í•¨ (ì‚¬ì‹¤ í™•ì¸ë¨)
- 80-99ì : ê·¼ê±°ë“¤ì´ ì£¼ì¥ì„ ê°•í•˜ê²Œ ë’·ë°›ì¹¨í•˜ì§€ë§Œ ì¼ë¶€ ì„¸ë¶€ì‚¬í•­ ë¶ˆì¼ì¹˜
- 60-79ì : ê·¼ê±°ë“¤ì´ ì£¼ì¥ì„ ë¶€ë¶„ì ìœ¼ë¡œ ë’·ë°›ì¹¨í•¨
- 40-59ì : ê·¼ê±°ë“¤ì´ ì£¼ì¥ê³¼ ê´€ë ¨ì€ ìˆìœ¼ë‚˜ ì§ì ‘ì  ë’·ë°›ì¹¨ ë¶€ì¡±
- 20-39ì : ê·¼ê±°ë“¤ì´ ì£¼ì¥ê³¼ ìƒì¶©í•˜ê±°ë‚˜ ë°˜ë°•í•¨ (í™˜ê° ê°€ëŠ¥ì„± ë†’ìŒ)
- 0-19ì : ê·¼ê±°ë“¤ì´ ì£¼ì¥ì„ ëª…í™•íˆ ë°˜ë°•í•¨ (í™˜ê° í™•ì‹¤)

ì¤‘ìš”:
- ê·¼ê±°ì˜ ê´€ë ¨ë„ ì ìˆ˜ë¥¼ ê³ ë ¤í•˜ì„¸ìš”
- ì—¬ëŸ¬ ë…ë¦½ì ì¸ ì¶œì²˜ê°€ ê°™ì€ ë‚´ìš©ì„ ë’·ë°›ì¹¨í•˜ë©´ ì‹ ë¢°ë„ê°€ ë†’ìŠµë‹ˆë‹¤
- ê·¼ê±°ê°€ ì£¼ì¥ì˜ í•µì‹¬ ë‚´ìš©ì„ ì§ì ‘ ì–¸ê¸‰í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
ì ìˆ˜: [0-100 ìˆ«ì]
ê·¼ê±°: [ì ìˆ˜ë¥¼ ë§¤ê¸´ ì´ìœ ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…]"""

        try:
            result = await judge.analyze_text(scoring_prompt)
            
            # ì ìˆ˜ ì¶”ì¶œ
            import re
            score_match = re.search(r'ì ìˆ˜:\s*(\d+)', result)
            reasoning_match = re.search(r'ê·¼ê±°:\s*(.+)', result, re.DOTALL)
            
            if score_match:
                score = float(score_match.group(1))
                reasoning = reasoning_match.group(1).strip() if reasoning_match else "No reasoning provided"
                
                # ê·¼ê±° ê°œìˆ˜ì— ë”°ë¥¸ ì‹ ë¢°ë„ ì¡°ì •
                if len(evidence_list) < 3:
                    score = score * 0.9  # ê·¼ê±°ê°€ ì ìœ¼ë©´ 10% ê°ì 
                    reasoning += f" (ê·¼ê±° ë¶€ì¡±ìœ¼ë¡œ 10% ê°ì : {len(evidence_list)}ê°œ)"
            else:
                score = 50.0
                reasoning = "Failed to parse score from LLM response"
            
            logger.info(f"Claim scored: {score:.1f} - {claim_text[:50]}...")

            final_score = max(0.0, min(100.0, score))

            # ìºì‹œì— ì €ì¥ (ì ìˆ˜ 70 ì´ìƒì´ë©´ verifiedë¡œ ê°„ì£¼)
            if self.grounding_cache:
                is_verified = final_score >= 70.0
                mcp_sources = [{'source': ev.get('source', ''), 'title': ev.get('title', '')} for ev in evidence_list[:3]]
                await self.grounding_cache.set(
                    claim_text,
                    is_verified=is_verified,
                    evidence=reasoning[:500],
                    mcp_sources=mcp_sources,
                    confidence=final_score / 100.0
                )
                logger.info(f"ğŸ’¾ [GroundingCache] SET - {claim_text[:40]}... (score: {final_score:.1f})")

            return {
                **evidence_data,
                'score': final_score,
                'reasoning': reasoning,
                'llm_response': result[:500],
                'evidence_count': len(evidence_list),
                'cache_hit': False
            }

        except Exception as e:
            logger.error(f"Claim scoring failed: {str(e)}")
            return {
                **evidence_data,
                'score': 50.0,
                'reasoning': f'Scoring failed: {str(e)}',
                'evidence_count': len(evidence_list),
                'cache_hit': False
            }
    
    def _get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total = self._cache_hits + self._cache_misses
        hit_rate = (self._cache_hits / total * 100) if total > 0 else 0
        return {
            "cache_hits": self._cache_hits,
            "cache_misses": self._cache_misses,
            "hit_rate": f"{hit_rate:.1f}%",
            "total_claims": total
        }

    def _calculate_final_score(self, claim_scores: List[Dict[str, Any]]) -> float:
        """ìµœì¢… ì ìˆ˜ ê³„ì‚°"""
        
        if not claim_scores:
            return 100.0  # ê²€ì¦í•  ì£¼ì¥ì´ ì—†ìœ¼ë©´ í™˜ê° ì—†ìŒ (100ì  = ì¢‹ìŒ)
        
        # ê° ì£¼ì¥ì˜ ì ìˆ˜ í‰ê· 
        scores = [result.get('score', 50.0) for result in claim_scores]
        
        # ê²€ì¦ ì ìˆ˜ í‰ê·  = ì‚¬ì‹¤ í™•ì¸ ì ìˆ˜
        # 100ì  = í™˜ê° ì—†ìŒ (ì¢‹ìŒ), 0ì  = í™˜ê° ë§ìŒ (ë‚˜ì¨)
        average_verification_score = sum(scores) / len(scores)
        
        return max(0.0, min(100.0, average_verification_score))