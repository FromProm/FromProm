#!/usr/bin/env python3
"""
Strands Framework í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (Supervisor Pattern)
"""

import asyncio
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_strands_supervisor_pattern():
    """Strands Supervisor Pattern í…ŒìŠ¤íŠ¸"""
    try:
        from app.orchestrator.context import ExecutionContext
        from app.agents.agent_pipeline import AgentPipeline
        from app.core.schemas import JobCreateRequest, ExampleInput, PromptType, RecommendedModel
        
        print("ğŸ¯ Strands Supervisor Pattern í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # Mock JobCreateRequest
        job_request = JobCreateRequest(
            prompt="í•œêµ­ì˜ ê²½ì œ ìƒí™©ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            example_inputs=[
                ExampleInput(content="í•œêµ­ ê²½ì œì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”", input_type="text")
            ],
            prompt_type=PromptType.TYPE_A,
            recommended_model=RecommendedModel.CLAUDE_SONNET_4_5,
            repeat_count=2,
            title="Strands Supervisor Pattern í…ŒìŠ¤íŠ¸",
            description="Claude Supervisor + Tool Workers + AI Worker í…ŒìŠ¤íŠ¸",
            user_id="strands_test"
        )
        
        # ExecutionContext ìƒì„±
        context = ExecutionContext()
        
        # Agent Pipeline (Strands Supervisor Pattern) ì‹¤í–‰
        pipeline = AgentPipeline(context)
        
        print("ğŸ“Š Strands Framework ì •ë³´:")
        strands_info = pipeline.get_strands_info()
        for key, value in strands_info.items():
            if isinstance(value, list):
                print(f"   {key}:")
                for item in value:
                    print(f"     - {item}")
            else:
                print(f"   {key}: {value}")
        
        print("\nğŸš€ Strands Supervisor Pattern ì‹¤í–‰ ì¤‘...")
        result = await pipeline.run(job_request)
        
        print(f"\nâœ… Strands Supervisor Pattern ì‹¤í–‰ ì™„ë£Œ!")
        print(f"   ìµœì¢… ì ìˆ˜: {result.final_score}")
        print(f"   ê°€ì¤‘ ì ìˆ˜: {result.weighted_scores}")
        
        # ê°œë³„ ì§€í‘œ í™•ì¸
        metrics = {
            'token_usage': result.token_usage,
            'information_density': result.information_density,
            'consistency': result.consistency,
            'model_variance': result.model_variance,
            'hallucination': result.hallucination,
            'relevance': result.relevance
        }
        
        print(f"\nğŸ“Š Worker ê²°ê³¼:")
        for name, metric in metrics.items():
            if metric:
                worker_type = "AI Worker" if name == "hallucination" else "Tool Worker"
                bedrock_tool_use = metric.details.get('bedrock_tool_use', False)
                method = "Bedrock Tool Use" if bedrock_tool_use else "Traditional"
                print(f"   {name}: {metric.score} ({worker_type} - {method})")
            else:
                print(f"   {name}: None âŒ")
        
        # í”¼ë“œë°± í™•ì¸
        if hasattr(result, 'feedback') and result.feedback:
            print(f"\nğŸ’¬ Supervisor í”¼ë“œë°±:")
            feedback = result.feedback
            if isinstance(feedback, dict):
                is_bedrock_feedback = feedback.get('bedrock_tool_use', False)
                feedback_type = "Bedrock Tool Use Feedback" if is_bedrock_feedback else "Traditional Feedback"
                print(f"   í”¼ë“œë°± íƒ€ì…: {feedback_type}")
                
                if 'overall_feedback' in feedback:
                    print(f"   ì¢…í•© í”¼ë“œë°±: {feedback['overall_feedback'][:200]}...")
        
        print(f"\nğŸ‰ Strands Supervisor Pattern í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"   - Supervisor: Claude (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜)")
        print(f"   - Tool Workers: 5ê°œ (ê³„ì‚° ì‘ì—…)")
        print(f"   - AI Worker: 1ê°œ (í™˜ê° íƒì§€)")
        print(f"   - Agent Core Ready: âœ…")
        
    except Exception as e:
        print(f"âŒ Strands Supervisor Pattern í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:")
        print(traceback.format_exc())

async def test_bedrock_tool_agent():
    """BedrockToolAgent ì§ì ‘ í…ŒìŠ¤íŠ¸"""
    try:
        from app.orchestrator.context import ExecutionContext
        from app.agents.bedrock_tool_agent import BedrockToolAgent
        from app.core.schemas import JobCreateRequest, ExampleInput, PromptType, RecommendedModel
        
        print("\nğŸ”§ BedrockToolAgent ì§ì ‘ í…ŒìŠ¤íŠ¸...")
        
        context = ExecutionContext()
        agent = BedrockToolAgent(context)
        
        job_request = JobCreateRequest(
            prompt="ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.",
            example_inputs=[
                ExampleInput(content="í…ŒìŠ¤íŠ¸ ì…ë ¥", input_type="text")
            ],
            prompt_type=PromptType.TYPE_B_TEXT,
            recommended_model=RecommendedModel.CLAUDE_SONNET_4_5,
            repeat_count=1,
            title="BedrockToolAgent í…ŒìŠ¤íŠ¸",
            description="ì§ì ‘ Agent í…ŒìŠ¤íŠ¸",
            user_id="direct_test"
        )
        
        print("   Claude Supervisor ì‹¤í–‰ ì¤‘...")
        result = await agent.evaluate_prompt(job_request)
        
        print(f"   âœ… ì§ì ‘ í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ì ìˆ˜: {result.final_score}")
        
    except Exception as e:
        print(f"   âŒ BedrockToolAgent í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

async def main():
    print("=" * 70)
    print("ğŸ¯ Strands Framework - Supervisor Pattern í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    await test_bedrock_tool_agent()
    await test_strands_supervisor_pattern()

if __name__ == "__main__":
    asyncio.run(main())